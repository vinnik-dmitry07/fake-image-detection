{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94f91db0ee1f4b9eb78941c41fd41799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29eac1ea6a5d4cfe8fb54c282474fa90",
              "IPY_MODEL_476601a814cf4a0db99dcd120a8c3bf1",
              "IPY_MODEL_42c5e35af1004cf097f1868f7ff80c72"
            ],
            "layout": "IPY_MODEL_a368ecce0ead47d6a51cfd0790bed3ca"
          }
        },
        "29eac1ea6a5d4cfe8fb54c282474fa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eba72f68f4347bca4cff44ed0746826",
            "placeholder": "​",
            "style": "IPY_MODEL_7963391cb3dd41b0becfee9161045ab5",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "476601a814cf4a0db99dcd120a8c3bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab87189e38e540b2badedebd47d69e58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5b4c4668fbf4acfa3c25988c0a56122",
            "value": 1
          }
        },
        "42c5e35af1004cf097f1868f7ff80c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09799a628c54611a9c218f924c09f86",
            "placeholder": "​",
            "style": "IPY_MODEL_a5a39f403acf4df4a146708df2404946",
            "value": " 1/1 [00:02&lt;00:00,  2.27s/it]"
          }
        },
        "a368ecce0ead47d6a51cfd0790bed3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "5eba72f68f4347bca4cff44ed0746826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7963391cb3dd41b0becfee9161045ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab87189e38e540b2badedebd47d69e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5b4c4668fbf4acfa3c25988c0a56122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c09799a628c54611a9c218f924c09f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a39f403acf4df4a146708df2404946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hUlqcesaUnN",
        "outputId": "7cdafb2e-d8df-495a-95e2-b4adfaabbbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'unilm'...\n",
            "remote: Enumerating objects: 7541, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 7541 (delta 91), reused 184 (delta 73), pack-reused 7317\u001b[K\n",
            "Receiving objects: 100% (7541/7541), 24.94 MiB | 28.28 MiB/s, done.\n",
            "Resolving deltas: 100% (3170/3170), done.\n",
            "HEAD is now at 1111fee Update gradio_app.py\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/microsoft/unilm.git\n",
        "!cd unilm && git reset --hard 1111fee"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/unilm/beit3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDQ4m8j_bHeq",
        "outputId": "8408eb72-fdab-43c9-8213-c04de9c29e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/unilm/beit3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sed -i 's/torch._six/torch/g' utils.py\n",
        "!sed -i 's/torchmetrics==0.7.3/torchmetrics==0.11.4/g' requirements.txt"
      ],
      "metadata": {
        "id": "qag9wRZKb2v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQN9e1_ubiRs",
        "outputId": "312e6804-c921-4292-c9e5-f47faabe1325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.6/444.6 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchscale (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://conversationhub.blob.core.windows.net/beit-share-public/beit3/pretraining/beit3_base_patch16_224.pth\n",
        "!wget https://conversationhub.blob.core.windows.net/beit-share-public/beit3/sentencepiece/beit3.spm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXOB3-Xge31n",
        "outputId": "a9e7e9ab-c912-4415-92a5-1f89eab82887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-05 00:57:11--  https://conversationhub.blob.core.windows.net/beit-share-public/beit3/pretraining/beit3_base_patch16_224.pth\n",
            "Resolving conversationhub.blob.core.windows.net (conversationhub.blob.core.windows.net)... 52.191.176.36\n",
            "Connecting to conversationhub.blob.core.windows.net (conversationhub.blob.core.windows.net)|52.191.176.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 554351015 (529M) [application/zip]\n",
            "Saving to: ‘beit3_base_patch16_224.pth’\n",
            "\n",
            "beit3_base_patch16_ 100%[===================>] 528.67M  27.8MB/s    in 23s     \n",
            "\n",
            "2023-06-05 00:57:35 (22.8 MB/s) - ‘beit3_base_patch16_224.pth’ saved [554351015/554351015]\n",
            "\n",
            "--2023-06-05 00:57:35--  https://conversationhub.blob.core.windows.net/beit-share-public/beit3/sentencepiece/beit3.spm\n",
            "Resolving conversationhub.blob.core.windows.net (conversationhub.blob.core.windows.net)... 52.191.176.36\n",
            "Connecting to conversationhub.blob.core.windows.net (conversationhub.blob.core.windows.net)|52.191.176.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356293 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘beit3.spm’\n",
            "\n",
            "beit3.spm           100%[===================>]   1.29M  2.31MB/s    in 0.6s    \n",
            "\n",
            "2023-06-05 00:57:36 (2.31 MB/s) - ‘beit3.spm’ saved [1356293/1356293]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "import sys\n",
        "from argparse import Namespace\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import utils\n",
        "from datasets import build_transform\n",
        "from modeling_utils import BEiT3Wrapper, _get_base_config\n",
        "from run_beit3_finetuning import get_args\n",
        "\n",
        "\n",
        "class BEiT3BinaryImageClassification(BEiT3Wrapper):\n",
        "    def __init__(self, args_: Namespace):\n",
        "        super().__init__(args=args_)\n",
        "        embed_dim = args_.encoder_embed_dim\n",
        "        self.fc_norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, 1)\n",
        "\n",
        "        self.fc_norm.apply(self._init_weights)\n",
        "        self.head.apply(self._init_weights)\n",
        "        init_scale = 0.001\n",
        "        if isinstance(self.head, nn.Linear):\n",
        "            self.head.weight.data.mul_(init_scale)\n",
        "            self.head.bias.data.mul_(init_scale)\n",
        "\n",
        "    def forward(self, image):\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "            x = self.beit3(textual_tokens=None, visual_tokens=image)['encoder_out']\n",
        "        t = x[:, 1:, :]\n",
        "        cls_x = self.fc_norm(t.mean(1))\n",
        "        return self.head(cls_x)\n",
        "\n",
        "\n",
        "sys.argv = [\n",
        "    'script.py',\n",
        "    '--model', 'beit3_base_patch16_224',\n",
        "    '--input_size', '224',\n",
        "    '--task', 'flickr30k',  # just because required\n",
        "    '--batch_size', '16',\n",
        "    '--sentencepiece_model', '/content/unilm/beit3/beit3.spm',\n",
        "    '--finetune', '/content/unilm/beit3/beit3_base_patch16_224.pth',\n",
        "    '--num_workers', '0',\n",
        "    '--randaug',  # augmentations\n",
        "]\n",
        "args = get_args()[0]\n",
        "\n",
        "beit_train_transform = build_transform(is_train=True, args=args)\n",
        "beit_eval_transform = build_transform(is_train=False, args=args)\n",
        "\n",
        "beit_args = _get_base_config(**vars(args))\n",
        "beit_wrapper = BEiT3BinaryImageClassification(beit_args)\n",
        "utils.load_model_and_may_interpolate(args.finetune, beit_wrapper, args.model_key, args.model_prefix)\n",
        "beit_wrapper.to(args.device)\n",
        "beit_wrapper.beit3.eval()"
      ],
      "metadata": {
        "id": "yVQHbiQja8VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/microsoft/torchscale@2b10135\n",
        "!pip install -qU timm pytorch_lightning"
      ],
      "metadata": {
        "id": "I2sW4bSzfauQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/settings/account > \"Create New Token\"\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir /root/.kaggle\n",
        "!mv kaggle.json /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d dmitryvinnik/artifact-60k-balanced\n",
        "!kaggle datasets download -d dmitryvinnik/rd-predict-dataset\n",
        "!kaggle datasets download -d dmitryvinnik/beit3-fake-image-detector\n",
        "!unzip -q artifact-60k-balanced.zip -d ./artifact_60k_balanced\n",
        "!mkdir rd_predict_dataset\n",
        "!unzip -q rd-predict-dataset.zip -d ./rd_predict_dataset/0\n",
        "!unzip -q beit3-fake-image-detector.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "XgBbjLH6la32",
        "outputId": "3e40c881-11fa-4658-97fc-304f8f5593c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-635e1f7f-feba-4d0f-87a0-aaa6402e7d2e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-635e1f7f-feba-4d0f-87a0-aaa6402e7d2e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading artifact-60k-balanced.zip to /content/unilm/beit3\n",
            " 96% 617M/643M [00:08<00:00, 79.5MB/s]\n",
            "100% 643M/643M [00:08<00:00, 78.3MB/s]\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading rd-predict-dataset.zip to /content/unilm/beit3\n",
            "  0% 0.00/397k [00:00<?, ?B/s]\n",
            "100% 397k/397k [00:00<00:00, 161MB/s]\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading beit3-fake-image-detector.zip to /content/unilm/beit3\n",
            " 98% 502M/511M [00:06<00:00, 66.7MB/s]\n",
            "100% 511M/511M [00:06<00:00, 84.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import copy\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchmetrics\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from timm.loss.binary_cross_entropy import BinaryCrossEntropy\n",
        "from torch.nn.functional import sigmoid\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n",
        "class Model(LightningModule):\n",
        "    def __init__(self, dataset, predict_dataset, train_transform, eval_transform, batch_size, learning_rate):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.beit_wrapper = beit_wrapper\n",
        "\n",
        "        self.criterion = BinaryCrossEntropy(smoothing=0.1)  # label smoothing\n",
        "        self.matt = torchmetrics.MatthewsCorrCoef(task='binary')\n",
        "\n",
        "        train_size = int(0.8 * len(dataset))\n",
        "        valid_size = len(dataset) - train_size\n",
        "        self.train_subset, self.val_subset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
        "        self.predict_dataset = predict_dataset\n",
        "\n",
        "        self.train_subset.dataset = copy(dataset)\n",
        "        self.train_subset.dataset.transform = train_transform\n",
        "        self.val_subset.dataset.transform = eval_transform\n",
        "        self.predict_dataset.transform = eval_transform\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_hat = self.beit_wrapper(x)\n",
        "        return sigmoid(y_hat).squeeze()\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        loss = self.criterion(self(x), y)\n",
        "        self.log('loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y = y.float()\n",
        "        y_hat = self(x)\n",
        "        self.log('val_loss', self.criterion(y_hat, y), on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('val_matt', self.matt(y_hat, y), on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "    # noinspection PyUnresolvedReferences\n",
        "    def on_train_epoch_end(self):\n",
        "        for name, params in self.named_parameters():\n",
        "            self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
        "            if params.grad is not None:\n",
        "                self.logger.experiment.add_histogram(name + '/grad', params.grad, self.current_epoch)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate, amsgrad=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_subset, num_workers=4, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_subset, num_workers=4, batch_size=self.batch_size)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.predict_dataset, num_workers=4, batch_size=len(self.predict_dataset))\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        x, _ = batch\n",
        "        return self(x)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    seed_everything(42, workers=True)\n",
        "\n",
        "    artifact_dataset = ImageFolder(root='./artifact_60k_balanced')\n",
        "    rd_predict_dataset = ImageFolder(root='./rd_predict_dataset')\n",
        "    model = Model(\n",
        "        dataset=artifact_dataset,\n",
        "        predict_dataset=rd_predict_dataset,\n",
        "        train_transform=beit_train_transform,\n",
        "        eval_transform=beit_eval_transform,\n",
        "        batch_size=256,\n",
        "        learning_rate=1e-4,\n",
        "    )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor='val_matt',\n",
        "        mode='max',\n",
        "        save_top_k=3,\n",
        "        save_last=True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        accelerator='gpu',\n",
        "        devices=1,\n",
        "        max_epochs=600,\n",
        "        precision=32,\n",
        "        deterministic=True,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    # trainer.fit(model)\n",
        "\n",
        "    predictions: torch.Tensor = trainer.predict(\n",
        "        model,\n",
        "        ckpt_path='epoch114-step19665.ckpt',\n",
        "    )\n",
        "\n",
        "    real_mask = (predictions[0] > 0.5).numpy().astype(bool)\n",
        "    df = pd.DataFrame(rd_predict_dataset.imgs)\n",
        "    df.loc[real_mask, 1] = 'real'\n",
        "    df.loc[~real_mask, 1] = 'fake'\n",
        "    df.to_csv('predictions.csv', index=False, header=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "94f91db0ee1f4b9eb78941c41fd41799",
            "29eac1ea6a5d4cfe8fb54c282474fa90",
            "476601a814cf4a0db99dcd120a8c3bf1",
            "42c5e35af1004cf097f1868f7ff80c72",
            "a368ecce0ead47d6a51cfd0790bed3ca",
            "5eba72f68f4347bca4cff44ed0746826",
            "7963391cb3dd41b0becfee9161045ab5",
            "ab87189e38e540b2badedebd47d69e58",
            "e5b4c4668fbf4acfa3c25988c0a56122",
            "c09799a628c54611a9c218f924c09f86",
            "a5a39f403acf4df4a146708df2404946"
          ]
        },
        "id": "A0PKqo1AfVR5",
        "outputId": "a3f465c4-24d7-42eb-a6f5-407b525e2286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: /content/unilm/beit3/lightning_logs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at epoch114-step19665.ckpt\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at epoch114-step19665.ckpt\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94f91db0ee1f4b9eb78941c41fd41799"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "CMvJ2-ZiDW-f",
        "outputId": "d5ff3df7-565b-4ca9-de8b-4f24d3dfc5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 0     1\n",
              "0   ./rd_predict_dataset/0/001.jpg  fake\n",
              "1   ./rd_predict_dataset/0/002.jpg  fake\n",
              "2   ./rd_predict_dataset/0/003.jpg  fake\n",
              "3   ./rd_predict_dataset/0/004.jpg  fake\n",
              "4   ./rd_predict_dataset/0/005.jpg  fake\n",
              "5   ./rd_predict_dataset/0/006.jpg  fake\n",
              "6   ./rd_predict_dataset/0/007.jpg  real\n",
              "7   ./rd_predict_dataset/0/008.png  real\n",
              "8   ./rd_predict_dataset/0/009.jpg  fake\n",
              "9   ./rd_predict_dataset/0/010.jpg  fake\n",
              "10  ./rd_predict_dataset/0/011.png  fake\n",
              "11  ./rd_predict_dataset/0/012.jpg  fake\n",
              "12  ./rd_predict_dataset/0/013.jpg  fake\n",
              "13  ./rd_predict_dataset/0/014.jpg  real\n",
              "14  ./rd_predict_dataset/0/015.jpg  fake\n",
              "15  ./rd_predict_dataset/0/016.jpg  fake\n",
              "16  ./rd_predict_dataset/0/017.jpg  fake\n",
              "17  ./rd_predict_dataset/0/018.jpg  fake\n",
              "18  ./rd_predict_dataset/0/019.jpg  fake\n",
              "19  ./rd_predict_dataset/0/020.jpg  fake\n",
              "20  ./rd_predict_dataset/0/021.jpg  fake\n",
              "21  ./rd_predict_dataset/0/022.jpg  fake"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7657f6c3-bd85-4a5c-8d6f-ef18bcb05d4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./rd_predict_dataset/0/001.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./rd_predict_dataset/0/002.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./rd_predict_dataset/0/003.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./rd_predict_dataset/0/004.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./rd_predict_dataset/0/005.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>./rd_predict_dataset/0/006.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>./rd_predict_dataset/0/007.jpg</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>./rd_predict_dataset/0/008.png</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>./rd_predict_dataset/0/009.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>./rd_predict_dataset/0/010.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>./rd_predict_dataset/0/011.png</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>./rd_predict_dataset/0/012.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>./rd_predict_dataset/0/013.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>./rd_predict_dataset/0/014.jpg</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>./rd_predict_dataset/0/015.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>./rd_predict_dataset/0/016.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>./rd_predict_dataset/0/017.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>./rd_predict_dataset/0/018.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>./rd_predict_dataset/0/019.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>./rd_predict_dataset/0/020.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>./rd_predict_dataset/0/021.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>./rd_predict_dataset/0/022.jpg</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7657f6c3-bd85-4a5c-8d6f-ef18bcb05d4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7657f6c3-bd85-4a5c-8d6f-ef18bcb05d4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7657f6c3-bd85-4a5c-8d6f-ef18bcb05d4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
